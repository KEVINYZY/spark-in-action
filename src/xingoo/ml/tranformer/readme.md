# tokenizer

用于分词，`RegexTokenizer`是最常用的分词规则，默认是\\s+，用符号来作为分割。

# stopWordsRemover

